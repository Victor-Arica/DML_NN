{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e94e755",
   "metadata": {},
   "source": [
    "# Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf3f51d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, LassoCV\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a87ae1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data loaded successfully\n",
      "    abdt  tg  inuidur1  inuidur2  female  black  hispanic  othrace  dep  q1  \\\n",
      "0  10824   0        18        18       0      0         0        0    2   0   \n",
      "1  10635   2         7         3       0      0         0        0    0   0   \n",
      "2  10551   5        18         6       1      0         0        0    0   0   \n",
      "3  10824   0         1         1       0      0         0        0    0   0   \n",
      "4  10747   0        27        27       0      0         0        0    0   0   \n",
      "\n",
      "   ...  q5  q6  recall  agelt35  agegt54  durable  nondurable  lusd  husd  \\\n",
      "0  ...   1   0       0        0        0        0           0     0     1   \n",
      "1  ...   0   0       0        1        0        0           0     1     0   \n",
      "2  ...   0   0       1        0        1        0           0     0     0   \n",
      "3  ...   1   0       0        0        0        0           0     1     0   \n",
      "4  ...   0   0       0        0        0        0           0     1     0   \n",
      "\n",
      "   muld  \n",
      "0     0  \n",
      "1     0  \n",
      "2     0  \n",
      "3     0  \n",
      "4     0  \n",
      "\n",
      "[5 rows x 23 columns] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# I. CLEANING AND SET-UP\n",
    "# ====================================================\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 0. Load data\n",
    "# ------------------------------\n",
    "file_path = r\"..\\..\\r\\input\\penn_jae.dat\"\n",
    "\n",
    "# Detect delimiter automatically\n",
    "df_raw = pd.read_csv(file_path, sep=r\"\\s+\", engine=\"python\")\n",
    "print(\"✓ Data loaded successfully\")\n",
    "print(df_raw.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61001f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.loc[df_raw[\"tg\"].isin([0, 4])].copy()\n",
    "df[\"T4\"] = (df[\"tg\"] == 4).astype(int)\n",
    "\n",
    "if \"inuidur1\" in df.columns:\n",
    "    df[\"y\"] = np.log(df[\"inuidur1\"])\n",
    "elif \"inuidur2\" in df.columns:\n",
    "    df[\"y\"] = np.log(df[\"inuidur2\"])\n",
    "elif \"inuidur\" in df.columns:\n",
    "    df[\"y\"] = np.log(df[\"inuidur\"])\n",
    "else:\n",
    "    raise ValueError(\"No se encontró la variable de ingreso.\")\n",
    "\n",
    "df[\"dep_0\"] = (df[\"dep\"] == 0).astype(int)\n",
    "df[\"dep_1\"] = (df[\"dep\"] == 1).astype(int)\n",
    "df[\"dep_2\"] = (df[\"dep\"] == 2).astype(int)\n",
    "\n",
    "x_vars = [\n",
    "    'female', 'black', 'othrace', 'dep_1', 'dep_2',\n",
    "    'q2', 'q3', 'q4', 'q5', 'q6',\n",
    "    'recall', 'agelt35', 'agegt54',\n",
    "    'durable', 'nondurable', 'lusd', 'husd'\n",
    "]\n",
    "\n",
    "x_vars = [v for v in x_vars if v in df.columns]\n",
    "\n",
    "X = df[x_vars].to_numpy()\n",
    "y = df[\"y\"].to_numpy()\n",
    "d = df[\"T4\"].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c425b11",
   "metadata": {},
   "source": [
    "# II. Parte 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "552a6f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Method",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Estimate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "SE",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "7c763cc4-cd2d-4b1b-b17f-b2954cb1ca4b",
       "rows": [
        [
         "0",
         "OLS",
         "-0.06825227806650924",
         "0.07891936998036578"
        ],
        [
         "1",
         "Lasso",
         "-0.07004482570758691",
         "0.07883947082856478"
        ],
        [
         "2",
         "RandomForest",
         "-0.09129364671645411",
         "0.09143440052378804"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Estimate</th>\n",
       "      <th>SE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OLS</td>\n",
       "      <td>-0.068252</td>\n",
       "      <td>0.078919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>-0.070045</td>\n",
       "      <td>0.078839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>-0.091294</td>\n",
       "      <td>0.091434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Method  Estimate        SE\n",
       "0           OLS -0.068252  0.078919\n",
       "1         Lasso -0.070045  0.078839\n",
       "2  RandomForest -0.091294  0.091434"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dml(y, d, X, n_folds=5, method_y=\"ols\", method_d=\"ols\"):\n",
    "\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=123)\n",
    "    thetas, ses = [], []\n",
    "\n",
    "    for train_idx, test_idx in kf.split(X):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        d_train, d_test = d[train_idx], d[test_idx]\n",
    "\n",
    "        # Modelo para E[Y|X]\n",
    "        if method_y == \"ols\":\n",
    "            mdl_y = LinearRegression().fit(X_train, y_train)\n",
    "            y_hat = mdl_y.predict(X_test)\n",
    "\n",
    "        elif method_y == \"lasso\":\n",
    "            mdl_y = LassoCV(cv=5).fit(X_train, y_train)\n",
    "            y_hat = mdl_y.predict(X_test)\n",
    "\n",
    "        elif method_y == \"rf\":\n",
    "            mdl_y = RandomForestRegressor().fit(X_train, y_train)\n",
    "            y_hat = mdl_y.predict(X_test)\n",
    "\n",
    "        # Modelo para E[D|X]\n",
    "        if method_d == \"ols\":\n",
    "            mdl_d = LinearRegression().fit(X_train, d_train)\n",
    "            d_hat = mdl_d.predict(X_test)\n",
    "\n",
    "        elif method_d == \"lasso\":\n",
    "            mdl_d = LassoCV(cv=5).fit(X_train, d_train)\n",
    "            d_hat = mdl_d.predict(X_test)\n",
    "\n",
    "        elif method_d == \"rf\":\n",
    "            mdl_d = RandomForestClassifier().fit(X_train, d_train)\n",
    "            d_hat = mdl_d.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Residuos\n",
    "        v_hat = y_test - y_hat\n",
    "        u_hat = d_test - d_hat\n",
    "\n",
    "        # Parámetro causal\n",
    "        theta = np.mean(u_hat * v_hat) / np.mean(u_hat * d_test)\n",
    "        thetas.append(theta)\n",
    "\n",
    "        # Error estándar\n",
    "        se = np.std(u_hat * v_hat) / (np.sqrt(len(test_idx)) * abs(np.mean(u_hat * d_test)))\n",
    "        ses.append(se)\n",
    "\n",
    "    return {\n",
    "        \"theta_hat\": np.mean(thetas),\n",
    "        \"se_hat\": np.mean(ses),\n",
    "        \"theta_folds\": thetas\n",
    "    }\n",
    "\n",
    "# ---- Estimaciones DML usando varios métodos ----\n",
    "\n",
    "results_dml = []\n",
    "\n",
    "res_ols = dml(y, d, X, method_y=\"ols\", method_d=\"ols\")\n",
    "results_dml.append((\"OLS\", res_ols[\"theta_hat\"], res_ols[\"se_hat\"]))\n",
    "\n",
    "res_lasso = dml(y, d, X, method_y=\"lasso\", method_d=\"lasso\")\n",
    "results_dml.append((\"Lasso\", res_lasso[\"theta_hat\"], res_lasso[\"se_hat\"]))\n",
    "\n",
    "res_rf = dml(y, d, X, method_y=\"rf\", method_d=\"rf\")\n",
    "results_dml.append((\"RandomForest\", res_rf[\"theta_hat\"], res_rf[\"se_hat\"]))\n",
    "\n",
    "# Resultado final en DataFrame\n",
    "\n",
    "results_dml = pd.DataFrame(results_dml, columns=[\"Method\", \"Estimate\", \"SE\"])\n",
    "results_dml \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "987109a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# III. DEFINE Y, D, X\n",
    "# ====================================================\n",
    "\n",
    "# Y: Outcome (definido en la limpieza como log(inuidur1))\n",
    "Y = df[\"y\"].values\n",
    "\n",
    "# D: Treatment\n",
    "D = df[\"T4\"].values\n",
    "\n",
    "# X: Covariates definidos en tu parte I\n",
    "x_vars = [\n",
    "    'female', 'black', 'othrace',\n",
    "    'dep_1', 'dep_2',\n",
    "    'q2', 'q3', 'q4', 'q5', 'q6',\n",
    "    'recall', 'agelt35', 'agegt54',\n",
    "    'durable', 'nondurable', 'lusd', 'husd'\n",
    "]\n",
    "\n",
    "# filtrar solo columnas que existen\n",
    "x_vars = [col for col in x_vars if col in df.columns]\n",
    "\n",
    "X = df[x_vars].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3d2d713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# IV. DML FUNCTION (Partially Linear Model)\n",
    "# ====================================================\n",
    "\n",
    "\n",
    "def dml(Y, D, X, ml_y, ml_d, K=2):\n",
    "\n",
    "    kf = KFold(n_splits=K, shuffle=True, random_state=123)\n",
    "\n",
    "    tilde_Y = np.zeros(len(Y))\n",
    "    tilde_D = np.zeros(len(D))\n",
    "\n",
    "    for train_idx, test_idx in kf.split(X):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        Y_train, Y_test = Y[train_idx], Y[test_idx]\n",
    "        D_train, D_test = D[train_idx], D[test_idx]\n",
    "\n",
    "        # Fit ML models\n",
    "        ml_y.fit(X_train, Y_train)\n",
    "        ml_d.fit(X_train, D_train)\n",
    "\n",
    "        # Predict m(X) and g(X)\n",
    "        m_hat = ml_y.predict(X_test)\n",
    "        g_hat = ml_d.predict(X_test)\n",
    "\n",
    "        # Residuals\n",
    "        tilde_Y[test_idx] = Y_test - m_hat\n",
    "        tilde_D[test_idx] = D_test - g_hat\n",
    "\n",
    "    # Final partialling out regression\n",
    "    theta = np.sum(tilde_D * tilde_Y) / np.sum(tilde_D * tilde_D)\n",
    "\n",
    "    # Standard error\n",
    "    resid = tilde_Y - theta * tilde_D\n",
    "    sigma2 = np.mean(resid**2)\n",
    "    se = np.sqrt(sigma2 / np.sum(tilde_D**2))\n",
    "\n",
    "    return theta, se\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6709862d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Theta",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Std.Error",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "eddf6378-4aed-4ca8-873e-3911223d3786",
       "rows": [
        [
         "0",
         "OLS",
         "-0.07989917183652365",
         "0.035138162283923614"
        ],
        [
         "1",
         "Lasso",
         "-0.07680644604082477",
         "0.03527818726690272"
        ],
        [
         "2",
         "Random Forest",
         "-0.09799475010177817",
         "0.0355005679703767"
        ],
        [
         "3",
         "Neural Net",
         "-0.06505204437163563",
         "0.03489888207275271"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Theta</th>\n",
       "      <th>Std.Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OLS</td>\n",
       "      <td>-0.079899</td>\n",
       "      <td>0.035138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>-0.076806</td>\n",
       "      <td>0.035278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>-0.097995</td>\n",
       "      <td>0.035501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neural Net</td>\n",
       "      <td>-0.065052</td>\n",
       "      <td>0.034899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model     Theta  Std.Error\n",
       "0            OLS -0.079899   0.035138\n",
       "1          Lasso -0.076806   0.035278\n",
       "2  Random Forest -0.097995   0.035501\n",
       "3     Neural Net -0.065052   0.034899"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "# ---------------------------\n",
    "# 1. OLS\n",
    "# ---------------------------\n",
    "ols_y = LinearRegression()\n",
    "ols_d = LinearRegression()\n",
    "theta, se = dml(Y, D, X, ols_y, ols_d)\n",
    "results.append([\"OLS\", theta, se])\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Lasso\n",
    "# ---------------------------\n",
    "lasso_y = LassoCV(cv=5, random_state=123)\n",
    "lasso_d = LassoCV(cv=5, random_state=123)\n",
    "theta, se = dml(Y, D, X, lasso_y, lasso_d)\n",
    "results.append([\"Lasso\", theta, se])\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Random Forest\n",
    "# ---------------------------\n",
    "rf_y = RandomForestRegressor(\n",
    "    n_estimators=500,\n",
    "    max_depth=None,\n",
    "    random_state=123\n",
    ")\n",
    "rf_d = RandomForestRegressor(\n",
    "    n_estimators=500,\n",
    "    max_depth=None,\n",
    "    random_state=123\n",
    ")\n",
    "theta, se = dml(Y, D, X, rf_y, rf_d)\n",
    "results.append([\"Random Forest\", theta, se])\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 4. Neural Network (MLP)\n",
    "# ---------------------------\n",
    "nn_y = MLPRegressor(\n",
    "    hidden_layer_sizes=(64, 64),\n",
    "    activation=\"relu\",\n",
    "    max_iter=2000,\n",
    "    random_state=123\n",
    ")\n",
    "nn_d = MLPRegressor(\n",
    "    hidden_layer_sizes=(64, 64),\n",
    "    activation=\"relu\",\n",
    "    max_iter=2000,\n",
    "    random_state=123\n",
    ")\n",
    "theta, se = dml(Y, D, X, nn_y, nn_d)\n",
    "results.append([\"Neural Net\", theta, se])\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# TABLE\n",
    "# ---------------------------\n",
    "table_results = pd.DataFrame(results, columns=[\"Model\", \"Theta\", \"Std.Error\"])\n",
    "table_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1bdbae",
   "metadata": {},
   "source": [
    "La estimación del efecto causal del tratamiento T4 sobre la duración de desempleo (medida como log(inuidur1)) se realizó utilizando el método Debiased Machine Learning (DML) con cross-fitting. Se aplicaron cuatro modelos diferentes para aproximar las funciones condicionales necesarias: OLS, Lasso, Random Forest y una Red Neuronal (MLP).\n",
    "\n",
    "Los resultados muestran que:\n",
    "\n",
    "En todos los modelos, el efecto estimado (theta) es negativo, lo cual sugiere que pertenecer al grupo de tratamiento reduce la duración del desempleo en promedio.\n",
    "\n",
    "Las estimaciones varían entre –0.098 y –0.065, dependiendo del modelo utilizado.\n",
    "\n",
    "El error estándar es relativamente estable y cercano a 0.035 en todos los casos, indicando una incertidumbre similar entre modelos.\n",
    "\n",
    "El modelo que predice un mayor impacto negativo es Random Forest (θ ≈ –0.098), mientras que el impacto menor proviene de la Red Neuronal (θ ≈ –0.065).\n",
    "\n",
    "OLS y Lasso producen estimaciones muy similares entre sí, alrededor de –0.078, lo que refleja estabilidad entre métodos lineales.\n",
    "\n",
    "En conjunto, los resultados sugieren que el tratamiento T4 está asociado con una disminución moderada en el logaritmo de la duración del desempleo. Dado que los modelos no-lineales (Random Forest y NN) ofrecen resultados más dispersos, los modelos lineales (OLS y Lasso) parecen proporcionar estimaciones más estables bajo el enfoque DML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a44890e",
   "metadata": {},
   "source": [
    "# III. Parte 2 Comparacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d223dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c100eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =======================================================\n",
    "#   DML SIN CROSS-FITTING\n",
    "# =======================================================\n",
    "\n",
    "def dml_no_cf(Y, D, X, ml_y, ml_d, train_fraction=0.7):\n",
    "\n",
    "    n = len(Y)\n",
    "    idx = np.arange(n)\n",
    "\n",
    "    # Train/Test split fijo (sin cross-fitting)\n",
    "    train_size = int(train_fraction * n)\n",
    "    np.random.seed(123)\n",
    "    train_idx = np.random.choice(idx, size=train_size, replace=False)\n",
    "    test_idx = np.setdiff1d(idx, train_idx)\n",
    "\n",
    "    # Entrenar modelos con el split único\n",
    "    ml_y.fit(X[train_idx], Y[train_idx])\n",
    "    ml_d.fit(X[train_idx], D[train_idx])\n",
    "\n",
    "    # Predicciones\n",
    "    y_hat_train = ml_y.predict(X[train_idx])\n",
    "    y_hat_test  = ml_y.predict(X[test_idx])\n",
    "\n",
    "    d_hat_train = ml_d.predict(X[train_idx])\n",
    "    d_hat_test  = ml_d.predict(X[test_idx])\n",
    "\n",
    "    # RMSE\n",
    "    rmse_y_train = np.sqrt(mean_squared_error(Y[train_idx], y_hat_train))\n",
    "    rmse_y_test  = np.sqrt(mean_squared_error(Y[test_idx],  y_hat_test))\n",
    "\n",
    "    rmse_d_train = np.sqrt(mean_squared_error(D[train_idx], d_hat_train))\n",
    "    rmse_d_test  = np.sqrt(mean_squared_error(D[test_idx],  d_hat_test))\n",
    "\n",
    "    # Residuos en test\n",
    "    v_hat = Y[test_idx] - y_hat_test\n",
    "    u_hat = D[test_idx] - d_hat_test\n",
    "\n",
    "    theta_hat = np.mean(u_hat * v_hat) / np.mean(u_hat * D[test_idx])\n",
    "    se_hat = np.std(u_hat * v_hat) / (np.sqrt(len(test_idx)) * abs(np.mean(u_hat * D[test_idx])))\n",
    "\n",
    "    return {\n",
    "        \"theta\": theta_hat,\n",
    "        \"se\": se_hat,\n",
    "        \"rmse_y_test\": rmse_y_test,\n",
    "        \"rmse_d_test\": rmse_d_test,\n",
    "        \"rmse_y_train\": rmse_y_train,\n",
    "        \"rmse_d_train\": rmse_d_train\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ba7d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_no_cf = []\n",
    "\n",
    "# -------------------------\n",
    "# OLS\n",
    "# -------------------------\n",
    "ols_y = LinearRegression()\n",
    "ols_d = LinearRegression()\n",
    "res = dml_no_cf(Y, D, X, ols_y, ols_d)\n",
    "results_no_cf.append([\"OLS\", res[\"theta\"], res[\"se\"], res[\"rmse_y_test\"], res[\"rmse_d_test\"]])\n",
    "\n",
    "# -------------------------\n",
    "# Lasso\n",
    "# -------------------------\n",
    "lasso_y = LassoCV(cv=5, random_state=123)\n",
    "lasso_d = LassoCV(cv=5, random_state=123)\n",
    "res = dml_no_cf(Y, D, X, lasso_y, lasso_d)\n",
    "results_no_cf.append([\"Lasso\", res[\"theta\"], res[\"se\"], res[\"rmse_y_test\"], res[\"rmse_d_test\"]])\n",
    "\n",
    "# -------------------------\n",
    "# Random Forest\n",
    "# -------------------------\n",
    "rf_y = RandomForestRegressor(n_estimators=500, random_state=123)\n",
    "rf_d = RandomForestRegressor(n_estimators=500, random_state=123)\n",
    "res = dml_no_cf(Y, D, X, rf_y, rf_d)\n",
    "results_no_cf.append([\"Random Forest\", res[\"theta\"], res[\"se\"], res[\"rmse_y_test\"], res[\"rmse_d_test\"]])\n",
    "\n",
    "# -------------------------\n",
    "# Neural Network\n",
    "# -------------------------\n",
    "nn_y = MLPRegressor(hidden_layer_sizes=(64, 64), max_iter=2000, random_state=123)\n",
    "nn_d = MLPRegressor(hidden_layer_sizes=(64, 64), max_iter=2000, random_state=123)\n",
    "res = dml_no_cf(Y, D, X, nn_y, nn_d)\n",
    "results_no_cf.append([\"Neural Net\", res[\"theta\"], res[\"se\"], res[\"rmse_y_test\"], res[\"rmse_d_test\"]])\n",
    "\n",
    "# Tabla final sin CF\n",
    "table_no_cf = pd.DataFrame(results_no_cf, columns=[\"Model\", \"Theta_NoCF\", \"SE_NoCF\", \"RMSE_Y_Test\", \"RMSE_D_Test\"])\n",
    "table_no_cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bf1cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_no_cf2 = table_no_cf[[\"Model\", \"Theta_NoCF\", \"SE_NoCF\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8290f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparacion= pd.merge(table_results, table_no_cf2, on=\"Model\", how=\"left\")\n",
    "comparacion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3abd1bf",
   "metadata": {},
   "source": [
    "### **Análisis Parte III – Comparación entre Cross-Fitting y No Cross-Fitting**\n",
    "\n",
    "### 1. Sobre el RMSE al predecir *y* y *d*\n",
    "Al estimar sin cross-fitting, los RMSE de $\\hat{y}$ y $\\hat{d}$ suelen ser **menores artificialmente**, especialmente en la muestra de entrenamiento, porque los modelos se ajustan sobre los mismos datos donde serán evaluados. Con cross-fitting, las predicciones fuera de muestra reflejan el verdadero desempeño predictivo, por lo que los RMSE son más realistas y tienden a ser un poco mayores.\n",
    "\n",
    "### 2. Razón por la cual una función produce un RMSE más bajo que la otra\n",
    "La función sin cross-fitting produce un RMSE más bajo debido al **overfitting**: el modelo memoriza patrones específicos del conjunto de entrenamiento, por lo que predice muy bien en los mismos datos usados para ajustar sus parámetros. En contraste, el cross-fitting evalúa siempre sobre datos no vistos, evitando ese sesgo optimista y entregando un RMSE más honesto sobre la capacidad de generalización.\n",
    "\n",
    "### 3. Problema de estimar sin cross-fitting\n",
    "Si usamos la estimación sin cross-fitting, el overfitting se transfiere directamente al cálculo de los residuales $\\tilde{Y}$ y $\\tilde{D}$, lo que sesga el estimador de $\\theta$. Esto rompe la propiedad clave del DML: la ortogonalidad entre los errores de predicción y la variable de tratamiento. Como consecuencia, el estimador resulta **sesgado e inconsistente**, pudiendo llevar a conclusiones"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CLL (3.11.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
